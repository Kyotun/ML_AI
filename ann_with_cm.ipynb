{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "869a5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2387dd5",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e74e7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Machine Learning A-Z (Codes and Datasets)/Part 8 - Deep Learning/Section 39 - Artificial Neural Networks (ANN)/Python/Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d607535",
   "metadata": {},
   "source": [
    "### Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3de1eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,3:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "def2b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3f98cd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272209a",
   "metadata": {},
   "source": [
    "### Change the categorical variables into dummy variables(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "61e48361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender\n",
       "0     Female\n",
       "1     Female\n",
       "2     Female\n",
       "3     Female\n",
       "4     Female\n",
       "...      ...\n",
       "9995    Male\n",
       "9996    Male\n",
       "9997  Female\n",
       "9998    Male\n",
       "9999  Female\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=x[:,2], columns=['Gender'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "69693d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender\n",
       "0          1\n",
       "1          1\n",
       "2          1\n",
       "3          1\n",
       "4          1\n",
       "...      ...\n",
       "9995       0\n",
       "9996       0\n",
       "9997       1\n",
       "9998       0\n",
       "9999       1\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = df['Gender'].map({'Female':1, 'Male':0})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c572aa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 1, ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 1, ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 1, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 1, ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 0, ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 1, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,2] = df['Gender']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "389734d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can use Labelencoder or .map\n",
    "\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#le = LabelEncoder()\n",
    "#x[:,2] = le.fit_transform(x[:,2])\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5c74fff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
      " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
      " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
      " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
      " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "x = np.array(ct.fit_transform(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54180543",
   "metadata": {},
   "source": [
    "### Split the data set into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3461d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ef90046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1fe31a",
   "metadata": {},
   "source": [
    "### Create the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "94276da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 1\n",
    "hidden_layer_size = 50\n",
    "input_size = 6\n",
    "\n",
    "#hyperparameters are based on experience\n",
    "\n",
    "#after TF2, keras integreted in TF\n",
    "\n",
    "#you can use which one you want to use\n",
    "\n",
    "#'relu' -> rectifier activation function\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#or\n",
    "\n",
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
    "\n",
    "#if we would have one hot or binary, we would choose differently of the units of output layer \n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "#when doing non-binary classification, when predicting more than two categories, activation of output -> softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c00fe",
   "metadata": {},
   "source": [
    "### Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d57d64bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for binary classification, loss -> binary_crossentropy\n",
    "#for non-binary classification, loss -> categorical_crossentropy\n",
    "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics  = ['accuracy'])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics  = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f6d636",
   "metadata": {},
   "source": [
    "### Train the ann on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f3ac5684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "800/800 - 1s - loss: 0.4047 - accuracy: 0.8300 - 965ms/epoch - 1ms/step\n",
      "Epoch 2/40\n",
      "800/800 - 1s - loss: 0.3538 - accuracy: 0.8547 - 645ms/epoch - 807us/step\n",
      "Epoch 3/40\n",
      "800/800 - 1s - loss: 0.3422 - accuracy: 0.8569 - 705ms/epoch - 881us/step\n",
      "Epoch 4/40\n",
      "800/800 - 1s - loss: 0.3381 - accuracy: 0.8602 - 703ms/epoch - 879us/step\n",
      "Epoch 5/40\n",
      "800/800 - 1s - loss: 0.3322 - accuracy: 0.8605 - 687ms/epoch - 859us/step\n",
      "Epoch 6/40\n",
      "800/800 - 1s - loss: 0.3279 - accuracy: 0.8656 - 666ms/epoch - 833us/step\n",
      "Epoch 7/40\n",
      "800/800 - 1s - loss: 0.3266 - accuracy: 0.8664 - 753ms/epoch - 942us/step\n",
      "Epoch 8/40\n",
      "800/800 - 1s - loss: 0.3238 - accuracy: 0.8680 - 648ms/epoch - 810us/step\n",
      "Epoch 9/40\n",
      "800/800 - 1s - loss: 0.3204 - accuracy: 0.8665 - 642ms/epoch - 802us/step\n",
      "Epoch 10/40\n",
      "800/800 - 1s - loss: 0.3180 - accuracy: 0.8691 - 654ms/epoch - 818us/step\n",
      "Epoch 11/40\n",
      "800/800 - 1s - loss: 0.3132 - accuracy: 0.8686 - 653ms/epoch - 816us/step\n",
      "Epoch 12/40\n",
      "800/800 - 1s - loss: 0.3111 - accuracy: 0.8705 - 648ms/epoch - 810us/step\n",
      "Epoch 13/40\n",
      "800/800 - 1s - loss: 0.3066 - accuracy: 0.8733 - 644ms/epoch - 805us/step\n",
      "Epoch 14/40\n",
      "800/800 - 1s - loss: 0.3026 - accuracy: 0.8730 - 674ms/epoch - 842us/step\n",
      "Epoch 15/40\n",
      "800/800 - 1s - loss: 0.2990 - accuracy: 0.8745 - 703ms/epoch - 879us/step\n",
      "Epoch 16/40\n",
      "800/800 - 1s - loss: 0.2969 - accuracy: 0.8741 - 696ms/epoch - 870us/step\n",
      "Epoch 17/40\n",
      "800/800 - 1s - loss: 0.2924 - accuracy: 0.8794 - 682ms/epoch - 853us/step\n",
      "Epoch 18/40\n",
      "800/800 - 1s - loss: 0.2892 - accuracy: 0.8765 - 689ms/epoch - 861us/step\n",
      "Epoch 19/40\n",
      "800/800 - 1s - loss: 0.2861 - accuracy: 0.8785 - 690ms/epoch - 862us/step\n",
      "Epoch 20/40\n",
      "800/800 - 1s - loss: 0.2821 - accuracy: 0.8810 - 692ms/epoch - 865us/step\n",
      "Epoch 21/40\n",
      "800/800 - 1s - loss: 0.2777 - accuracy: 0.8845 - 709ms/epoch - 886us/step\n",
      "Epoch 22/40\n",
      "800/800 - 1s - loss: 0.2744 - accuracy: 0.8827 - 681ms/epoch - 851us/step\n",
      "Epoch 23/40\n",
      "800/800 - 1s - loss: 0.2699 - accuracy: 0.8852 - 693ms/epoch - 867us/step\n",
      "Epoch 24/40\n",
      "800/800 - 1s - loss: 0.2685 - accuracy: 0.8863 - 796ms/epoch - 994us/step\n",
      "Epoch 25/40\n",
      "800/800 - 1s - loss: 0.2658 - accuracy: 0.8871 - 704ms/epoch - 880us/step\n",
      "Epoch 26/40\n",
      "800/800 - 1s - loss: 0.2616 - accuracy: 0.8869 - 741ms/epoch - 927us/step\n",
      "Epoch 27/40\n",
      "800/800 - 1s - loss: 0.2575 - accuracy: 0.8929 - 732ms/epoch - 915us/step\n",
      "Epoch 28/40\n",
      "800/800 - 1s - loss: 0.2540 - accuracy: 0.8907 - 712ms/epoch - 890us/step\n",
      "Epoch 29/40\n",
      "800/800 - 1s - loss: 0.2516 - accuracy: 0.8915 - 708ms/epoch - 886us/step\n",
      "Epoch 30/40\n",
      "800/800 - 1s - loss: 0.2464 - accuracy: 0.8949 - 683ms/epoch - 853us/step\n",
      "Epoch 31/40\n",
      "800/800 - 1s - loss: 0.2468 - accuracy: 0.8928 - 682ms/epoch - 853us/step\n",
      "Epoch 32/40\n",
      "800/800 - 1s - loss: 0.2381 - accuracy: 0.8976 - 675ms/epoch - 844us/step\n",
      "Epoch 33/40\n",
      "800/800 - 1s - loss: 0.2382 - accuracy: 0.9011 - 695ms/epoch - 869us/step\n",
      "Epoch 34/40\n",
      "800/800 - 1s - loss: 0.2353 - accuracy: 0.8999 - 690ms/epoch - 862us/step\n",
      "Epoch 35/40\n",
      "800/800 - 1s - loss: 0.2307 - accuracy: 0.9038 - 679ms/epoch - 849us/step\n",
      "Epoch 36/40\n",
      "800/800 - 1s - loss: 0.2265 - accuracy: 0.9051 - 717ms/epoch - 897us/step\n",
      "Epoch 37/40\n",
      "800/800 - 1s - loss: 0.2242 - accuracy: 0.9043 - 678ms/epoch - 847us/step\n",
      "Epoch 38/40\n",
      "800/800 - 1s - loss: 0.2228 - accuracy: 0.9019 - 675ms/epoch - 844us/step\n",
      "Epoch 39/40\n",
      "800/800 - 1s - loss: 0.2167 - accuracy: 0.9105 - 688ms/epoch - 861us/step\n",
      "Epoch 40/40\n",
      "800/800 - 1s - loss: 0.2149 - accuracy: 0.9109 - 677ms/epoch - 846us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd0b1b82e0>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "epochs = 40\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping()\n",
    "\n",
    "ann.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, verbose=2)\n",
    "#model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4553e6c4",
   "metadata": {},
   "source": [
    "### Predicting the result of a single observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "71356dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "[[0.01139096]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "#predict method waits 2D array therefore [[]]\n",
    "#we need to scale the observation too\n",
    "print(ann.predict(sc.transform([[1,0,0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n",
    "print(ann.predict(sc.transform([[1,0,0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)\n",
    "#False -> not leaving the bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba84a3",
   "metadata": {},
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8cc25cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 653us/step\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a02b84",
   "metadata": {},
   "source": [
    "### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f93bc5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1445  150]\n",
      " [ 171  234]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8395"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
