{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022bd525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58aed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('ml-1m-ae/movies.dat', sep='::', header=None, engine='python', encoding='latin-1')\n",
    "users = pd.read_csv('ml-1m-ae/users.dat', sep='::', header=None, engine='python', encoding='latin-1')\n",
    "ratings = pd.read_csv('ml-1m-ae/ratings.dat', sep='::', header=None, engine='python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b2a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('ml-100k-ae/u1.base', delimiter='\\t')\n",
    "training_set = np.array(training_set, dtype = 'int')\n",
    "test_set = pd.read_csv('ml-100k-ae/u1.test', delimiter='\\t')\n",
    "test_set = np.array(test_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b41de9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c50c385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855d718a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d95749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users+1):\n",
    "        if (data[id_users] == data[id_users+1]):\n",
    "            id_movies = data[:,1]\n",
    "        if (data[id_users] == data[id_users+1]):\n",
    "            id_ratings = data[:,2]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies -1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e96a8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_2(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users+1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies -1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "780e3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = convert_2(training_set)\n",
    "test_set = convert_2(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d9e15fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c804e4ed",
   "metadata": {},
   "source": [
    "### Creating the architecture of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d4af45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a class to specify and define the behaviours of our AE (to give instructions)\n",
    "# Object of this class will be an AE\n",
    "# Inheritence to use all the functions of the parent class\n",
    "# SAE -> Stacked Auto Encoders\n",
    "# We have several hidden layers -> several encodings of the input vector features\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self, ): # Put nothing after the comma, cause we have inheritence\n",
    "        \n",
    "        super(SAE, self).__init__() # Get the functions/methods of the module\n",
    "        \n",
    "        ## nn is module, Linear and Sigmoid are classes of the nn module\n",
    "        \n",
    "        self.fc1 = nn.Linear(nb_movies, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, nb_movies)\n",
    "        # The next function get the output of the last function as input\n",
    "        # nb_movies - 20neuron - 10neuron - 20 neuron - nb_movies -> these are the layers\n",
    "        \n",
    "        self.activation = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf9219",
   "metadata": {},
   "source": [
    "### Training the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ac112a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :1 loss: tensor(1.7709)\n",
      "epoch :2 loss: tensor(1.0967)\n",
      "epoch :3 loss: tensor(1.0535)\n",
      "epoch :4 loss: tensor(1.0382)\n",
      "epoch :5 loss: tensor(1.0310)\n",
      "epoch :6 loss: tensor(1.0265)\n",
      "epoch :7 loss: tensor(1.0238)\n",
      "epoch :8 loss: tensor(1.0219)\n",
      "epoch :9 loss: tensor(1.0206)\n",
      "epoch :10 loss: tensor(1.0197)\n",
      "epoch :11 loss: tensor(1.0189)\n",
      "epoch :12 loss: tensor(1.0182)\n",
      "epoch :13 loss: tensor(1.0179)\n",
      "epoch :14 loss: tensor(1.0174)\n",
      "epoch :15 loss: tensor(1.0171)\n",
      "epoch :16 loss: tensor(1.0168)\n",
      "epoch :17 loss: tensor(1.0166)\n",
      "epoch :18 loss: tensor(1.0163)\n",
      "epoch :19 loss: tensor(1.0167)\n",
      "epoch :20 loss: tensor(1.0160)\n",
      "epoch :21 loss: tensor(1.0158)\n",
      "epoch :22 loss: tensor(1.0160)\n",
      "epoch :23 loss: tensor(1.0157)\n",
      "epoch :24 loss: tensor(1.0156)\n",
      "epoch :25 loss: tensor(1.0157)\n",
      "epoch :26 loss: tensor(1.0156)\n",
      "epoch :27 loss: tensor(1.0154)\n",
      "epoch :28 loss: tensor(1.0150)\n",
      "epoch :29 loss: tensor(1.0127)\n",
      "epoch :30 loss: tensor(1.0114)\n",
      "epoch :31 loss: tensor(1.0089)\n",
      "epoch :32 loss: tensor(1.0070)\n",
      "epoch :33 loss: tensor(1.0042)\n",
      "epoch :34 loss: tensor(1.0042)\n",
      "epoch :35 loss: tensor(1.0009)\n",
      "epoch :36 loss: tensor(1.0005)\n",
      "epoch :37 loss: tensor(0.9970)\n",
      "epoch :38 loss: tensor(0.9961)\n",
      "epoch :39 loss: tensor(0.9927)\n",
      "epoch :40 loss: tensor(0.9936)\n",
      "epoch :41 loss: tensor(0.9890)\n",
      "epoch :42 loss: tensor(0.9881)\n",
      "epoch :43 loss: tensor(0.9839)\n",
      "epoch :44 loss: tensor(0.9843)\n",
      "epoch :45 loss: tensor(0.9849)\n",
      "epoch :46 loss: tensor(0.9859)\n",
      "epoch :47 loss: tensor(0.9832)\n",
      "epoch :48 loss: tensor(0.9810)\n",
      "epoch :49 loss: tensor(0.9799)\n",
      "epoch :50 loss: tensor(0.9784)\n",
      "epoch :51 loss: tensor(0.9752)\n",
      "epoch :52 loss: tensor(0.9791)\n",
      "epoch :53 loss: tensor(0.9723)\n",
      "epoch :54 loss: tensor(0.9759)\n",
      "epoch :55 loss: tensor(0.9725)\n",
      "epoch :56 loss: tensor(0.9726)\n",
      "epoch :57 loss: tensor(0.9709)\n",
      "epoch :58 loss: tensor(0.9682)\n",
      "epoch :59 loss: tensor(0.9696)\n",
      "epoch :60 loss: tensor(0.9656)\n",
      "epoch :61 loss: tensor(0.9630)\n",
      "epoch :62 loss: tensor(0.9660)\n",
      "epoch :63 loss: tensor(0.9630)\n",
      "epoch :64 loss: tensor(0.9615)\n",
      "epoch :65 loss: tensor(0.9624)\n",
      "epoch :66 loss: tensor(0.9697)\n",
      "epoch :67 loss: tensor(0.9689)\n",
      "epoch :68 loss: tensor(0.9618)\n",
      "epoch :69 loss: tensor(0.9582)\n",
      "epoch :70 loss: tensor(0.9608)\n",
      "epoch :71 loss: tensor(0.9607)\n",
      "epoch :72 loss: tensor(0.9531)\n",
      "epoch :73 loss: tensor(0.9531)\n",
      "epoch :74 loss: tensor(0.9563)\n",
      "epoch :75 loss: tensor(0.9550)\n",
      "epoch :76 loss: tensor(0.9531)\n",
      "epoch :77 loss: tensor(0.9523)\n",
      "epoch :78 loss: tensor(0.9527)\n",
      "epoch :79 loss: tensor(0.9531)\n",
      "epoch :80 loss: tensor(0.9541)\n",
      "epoch :81 loss: tensor(0.9503)\n",
      "epoch :82 loss: tensor(0.9484)\n",
      "epoch :83 loss: tensor(0.9538)\n",
      "epoch :84 loss: tensor(0.9513)\n",
      "epoch :85 loss: tensor(0.9467)\n",
      "epoch :86 loss: tensor(0.9492)\n",
      "epoch :87 loss: tensor(0.9465)\n",
      "epoch :88 loss: tensor(0.9468)\n",
      "epoch :89 loss: tensor(0.9431)\n",
      "epoch :90 loss: tensor(0.9457)\n",
      "epoch :91 loss: tensor(0.9427)\n",
      "epoch :92 loss: tensor(0.9463)\n",
      "epoch :93 loss: tensor(0.9412)\n",
      "epoch :94 loss: tensor(0.9421)\n",
      "epoch :95 loss: tensor(0.9403)\n",
      "epoch :96 loss: tensor(0.9416)\n",
      "epoch :97 loss: tensor(0.9384)\n",
      "epoch :98 loss: tensor(0.9411)\n",
      "epoch :99 loss: tensor(0.9379)\n",
      "epoch :100 loss: tensor(0.9399)\n",
      "epoch :101 loss: tensor(0.9366)\n",
      "epoch :102 loss: tensor(0.9385)\n",
      "epoch :103 loss: tensor(0.9370)\n",
      "epoch :104 loss: tensor(0.9381)\n",
      "epoch :105 loss: tensor(0.9355)\n",
      "epoch :106 loss: tensor(0.9364)\n",
      "epoch :107 loss: tensor(0.9349)\n",
      "epoch :108 loss: tensor(0.9353)\n",
      "epoch :109 loss: tensor(0.9338)\n",
      "epoch :110 loss: tensor(0.9346)\n",
      "epoch :111 loss: tensor(0.9331)\n",
      "epoch :112 loss: tensor(0.9337)\n",
      "epoch :113 loss: tensor(0.9321)\n",
      "epoch :114 loss: tensor(0.9328)\n",
      "epoch :115 loss: tensor(0.9311)\n",
      "epoch :116 loss: tensor(0.9322)\n",
      "epoch :117 loss: tensor(0.9310)\n",
      "epoch :118 loss: tensor(0.9316)\n",
      "epoch :119 loss: tensor(0.9299)\n",
      "epoch :120 loss: tensor(0.9313)\n",
      "epoch :121 loss: tensor(0.9292)\n",
      "epoch :122 loss: tensor(0.9302)\n",
      "epoch :123 loss: tensor(0.9285)\n",
      "epoch :124 loss: tensor(0.9294)\n",
      "epoch :125 loss: tensor(0.9278)\n",
      "epoch :126 loss: tensor(0.9288)\n",
      "epoch :127 loss: tensor(0.9269)\n",
      "epoch :128 loss: tensor(0.9280)\n",
      "epoch :129 loss: tensor(0.9264)\n",
      "epoch :130 loss: tensor(0.9267)\n",
      "epoch :131 loss: tensor(0.9260)\n",
      "epoch :132 loss: tensor(0.9272)\n",
      "epoch :133 loss: tensor(0.9247)\n",
      "epoch :134 loss: tensor(0.9257)\n",
      "epoch :135 loss: tensor(0.9244)\n",
      "epoch :136 loss: tensor(0.9248)\n",
      "epoch :137 loss: tensor(0.9233)\n",
      "epoch :138 loss: tensor(0.9243)\n",
      "epoch :139 loss: tensor(0.9226)\n",
      "epoch :140 loss: tensor(0.9238)\n",
      "epoch :141 loss: tensor(0.9223)\n",
      "epoch :142 loss: tensor(0.9233)\n",
      "epoch :143 loss: tensor(0.9219)\n",
      "epoch :144 loss: tensor(0.9223)\n",
      "epoch :145 loss: tensor(0.9214)\n",
      "epoch :146 loss: tensor(0.9223)\n",
      "epoch :147 loss: tensor(0.9207)\n",
      "epoch :148 loss: tensor(0.9217)\n",
      "epoch :149 loss: tensor(0.9199)\n",
      "epoch :150 loss: tensor(0.9218)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 150\n",
    "for epoch in range (1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    \n",
    "    #we will use RMSE at the end and RMSE is a float. That's why we use float \n",
    "    s = 0. # number of users who rated at least one movie\n",
    "    \n",
    "    for id_user in range (nb_users):\n",
    "        \n",
    "        # Add a fake dimension for functions\n",
    "        # index of fake dimension is 0\n",
    "        # we create batch\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        \n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data>0) > 0:\n",
    "            output = sae(input)\n",
    "            # GD won't be computed in target, it'll computed just in input vector\n",
    "            target.require_grad = False\n",
    "            \n",
    "            # zero values don't have impact on the update of the different weights\n",
    "            # before the loss we make them 0 to save comp power\n",
    "            output[target == 0] = 0 \n",
    "            \n",
    "            # calculate the loss func.\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # number of all movies divided by number of rated movies\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data>0) + 1e-10)\n",
    "            \n",
    "            # increase or decrease the weights? ->backward method\n",
    "            # direction of the optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            # loss data is the square error, that's why we take sqrt to get one degree loss\n",
    "            train_loss  += np.sqrt(loss.data*mean_corrector)\n",
    "            \n",
    "            # if user rated, increase s\n",
    "            s += 1.\n",
    "            \n",
    "            \n",
    "            optimizer.step() # intensity/amount of the updates\n",
    "    print('epoch :' + str(epoch) + ' loss: ' + str(train_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "285f5ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9184)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "\n",
    "#we will use RMSE at the end and RMSE is a float. That's why we use float \n",
    "s = 0. # number of users who rated at least one movie\n",
    "for id_user in range (nb_users): \n",
    "    \n",
    "    # Add a fake dimension for functions\n",
    "    # index of fake dimension is 0\n",
    "    # we create batch\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "      \n",
    "    target = input.clone()\n",
    "    if torch.sum(target.data>0) > 0:\n",
    "        output = sae(input)\n",
    "        # GD won't be computed in target, it'll computed just in input vector\n",
    "        target.require_grad = False\n",
    "        # zero values don't have impact on the update of the different weights\n",
    "        # before the loss we make them 0 to save comp power\n",
    "        output[target == 0] = 0 \n",
    "\n",
    "        # calculate the loss func.\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # number of all movies divided by number of rated movies\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data>0) + 1e-10)\n",
    "\n",
    "        # loss data is the square error, that's why we take sqrt to get one degree loss\n",
    "        test_loss  += np.sqrt(loss.data*mean_corrector)\n",
    "\n",
    "        # if user rated, increase s\n",
    "        s += 1.\n",
    "print('loss: ' + str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34c052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
